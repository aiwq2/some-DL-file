### 实验四：评论情感分类

---

#### 一、实验目的
1. 进一步加深对卷积神经网络基本原理的理解。
2. 掌握卷积神经网络处理文本的各项技术。
3. 掌握文本分类模型 Text-CNN 的架构和原理。

#### 二、实验环境
本次编程实验主要基于miniconda和pytorch框架进行，使用的各个库的版本号如下：
- python 3.7.16
- pytorch 1.10.0
- torchvision 0.11.0
- numpy 1.21.6
- tensorboard 2.11.2
- cuda 11.8

#### 三、数据准备与模型构建
**数据准备**

---
根据老师给定的数据集构造词典，得到word2id和id2word，word2id为单词到id的对应，id2word为id到单词的对应
```python
def build_word2id(trainpath, validatepath, testpath):
    word2id = {'_PAD_': 0}
    id2word = {0: '_PAD_'}
    path=[trainpath,validatepath,testpath]
    for _path in path:
        with open(_path, encoding='utf-8') as f:
            for line in f.readlines():
                sp=line.strip().split()
                for word in sp[1:]:
                    if word not in word2id.keys():
                        word2id[word] = len(word2id)
    # 也可以选择写入到文件中去，但是这里我们暂时保存在内存中
    # with open(file, 'w', encoding='utf-8') as f:
    #     for w in word2id:
    #         f.write(w+'\t')
    #         f.write(str(word2id[w]))
    #         f.write('\n')
    for key, val in word2id.items():
        id2word[val] = key
    return word2id, id2word
```
然后基于预训练好的 word2vec 构建训练语料中所含词语的 id2vec，后面后面的embedding层进行词嵌入
```python
def build_word2vec(word2vec_pretrained, word2id, save_to_path=None):
    n_words = max(word2id.values()) + 1
    model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_pretrained, binary=True)
    id_vecs = np.array(np.random.uniform(-1., 1., [n_words, model.vector_size]))
    for word in word2id.keys():
        try:
            id_vecs[word2id[word]] = model[word]
        except KeyError:
            pass
    if save_to_path:
        with open(save_to_path, 'w', encoding='utf-8') as f:
            for vec in id_vecs:
                vec = [str(w) for w in vec]
                f.write(' '.join(vec))
                f.write('\n')
    # 如果不加这一句，会报错"AttributeError: 'numpy.ndarray' object has no attribute 'dim'"
    id_vecs = torch.from_numpy(id_vecs)
    return id_vecs
```
**模型构建**

---

创建一个继承自 nn.Module 的类，在这个类的_init_( )中定义网络结构，在 forward 中定义前向传播过程。在本次实验中，自己构建了一个TextCNN网络结构，其中包含 Embedding层、卷积层、dropout层和全连接层四个网络层，其中embedding层载入预训练好了的词嵌入模型，也就是前面提到的id2vec，代码如下：
```python
import torch
from torch import nn
import torch.nn.functional as F
from .BasicModule import BasicModule

class TextCNN2(BasicModule):
    def __init__(self, vocab_size, embed_size, kernel_sizes, num_channels,pre_weight=None,
    **kwargs):
        super(TextCNN2, self).__init__(**kwargs)
        self.modelName = 'TextCNN'
        self.embedding = nn.Embedding(vocab_size, embed_size)
        # 这个嵌⼊层不需要训练
        self.constant_embedding = nn.Embedding(vocab_size, embed_size)
        if pre_weight is not None:
            self.embedding.from_pretrained(pre_weight)
            self.constant_embedding.from_pretrained(pre_weight)
            self.embedding.weight.requires_grad=True
            self.constant_embedding.weight.requires_grad=False
        self.dropout = nn.Dropout(0.5)
        self.decoder = nn.Linear(sum(num_channels), 2)
        # 最⼤时间汇聚层没有参数，因此可以共享此实例
        self.pool = nn.AdaptiveAvgPool1d(1)
        self.relu = nn.ReLU()
        # 创建多个⼀维卷积层
        self.convs = nn.ModuleList()
        for c, k in zip(num_channels, kernel_sizes):
            self.convs.append(nn.Conv1d(2 * embed_size, c, k))

    def forward(self, inputs):
        # 沿着向量维度将两个嵌⼊层连结起来，
        # 每个嵌⼊层的输出形状都是（批量⼤⼩，词元数量，词元向量维度）连结起来
        embeddings = torch.cat((
        self.embedding(inputs), self.constant_embedding(inputs)), dim=2)
        # 根据⼀维卷积层的输⼊格式，重新排列张量，以便通道作为第2维
        embeddings = embeddings.permute(0, 2, 1)# (批量⼤⼩，词元向量维度*2,词元数量)
        # 每个⼀维卷积层在最⼤时间汇聚层合并后，获得的张量形状是（批量⼤⼩，通道数，1）
        # 删除最后⼀个维度并沿通道维度连结
        encoding = torch.cat([
        torch.squeeze(self.relu(self.pool(conv(embeddings))), dim=-1) for conv in self.convs], dim=1)# (批量大小，sum(num_channels))
        outputs = self.decoder(self.dropout(encoding))
        return outputs
```
#### 四、实验过程及结果
**模型训练**
模型训练包括定义模型、设置优化器和损失函数、获取模型输出、计算误
差、误差反向传播等步骤
**实验一：**
在本次代码中，采用的参数均保存在Config模块下Config类中，这样可以便于更加快捷地设置超参数而不必更改代码的主体部分，实验一中的设置为
>- 优化器：采用Adm梯度下降优化器
>- 损失函数：采用 CrossEntropyLoss 交叉熵损失函数
>- 超参设置： batch_size=100，num_epochs=10，lr=0.001，embedding_dim = 50，vocab_size = 59290，hidden_dim = 256

>- 补充说明：lr利用schedur中的ReduceLROnPlateau进行控制，在5轮损失不下降的平台区缩小为0.01；受限于单机单卡的限制，batch_size的值不能设置太大

得到的实验结果如下图示
![图 3](../images/d3f0f9b26dd42898978f97538b355d0d17b7a5b394ff841f63db00d68f3b2090.png)  
![图 4](../images/6efcddc212d88f9c0198d3aa1c9956e7c39d536d0bd1a14919bc15fd93067608.png)  

我们可以看到其中测试准确率达到83.2%，同时利用sklearn库中的confusion_matrix，获得混淆矩阵如上图所示，其中包含了精确率，准确率，召回率，准确率和f1分数等，最后用seaborn库绘制出matric图像如下图所示
![图 6](../images/e41a5a2c903fcb26e838d526cc3689c7a054cb2021b4989e0089cc5db3e6cfc1.png)  


---

**小结**
通过这次实验，自己学会了利用 Pytorch 深度学习框架实现情感分类，深刻认识了TextCNN网络模型，以及其如何进行构建等，增加了对于卷积神经网络的理解。对于深度学习的整个流程，包括数据预处理、网络模型构建、模型训练、scheduler、pytorch下model模块的使用等方面都有了更深层次的理解，代码的组织编写水平也有了很大的提高，对于后续实验起到了很好的启发作用，受益匪浅！
